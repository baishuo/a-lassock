#系统的主配置文件
system {
  # 采集器名称,不设默认为HOST名;
  name: "lassock-lily"
  #本机ip或者hostname，如果没设置，则默认使用hostname
  # host: "aleiyeB"
  #ip : "10.7.0.150"
  #mac : "FFFFFFFFFFFF"
  authkey: ""
}
remote {
  zookeeper.url: "localhost:2181"
  host: "localhost"
  #aleiye-server监控端口
}

#配置监听器
liveness {
 	#class: "com.aleiye.lassock.liveness.ZkLiveness"
	connectionString : "@<remote.zookeeper.url>"
	coursefile:"template/file_course.json"
    class: "com.aleiye.lassock.liveness.FilePickLiveness"
}
live: {
	baskets {
		basket0 {
			name : simple
			class : "com.aleiye.lassock.live.basket.MemoryQueueBasket"
		}
	}
	bazaars {
		#bazaar0 {
		#	name : logger
		#	class : "com.aleiye.lassock.live.bazaar.LoggerBazaar"
		#}
		bazaar0 {
			zkhost : "@<remote.zookeeper.url>"
			name : kafka
			class : "com.aleiye.lassock.live.bazaar.KafkaBazaar"
		}
	}
}
#采集监控配置
monitor {
	enabled:true
 	sysname:lassock
    port:9981
    target : {
    	enabled:true
    	host : "10.0.1.35"
		port : 9982
		sysname: "collectorMonitor",
		actorname: "monitor"
    }
}
#执行线程池
executor {
  size: 100,
  maxSize: 100,
  #毫秒
  keepAliveTime: 60000,
  queueSize: 3000
}

#标记类型
marker {
  enabled: true,
  class: "com.aleiye.lassock.live.mark.FileMarker",
  filePath: "temp/mark.ofs",
  period: 3000
}

data.storage {
  #M(only memory),D(only disk),MD(memory and disk),JDBC(only jdbc),MJDBC(memory and jdbc)
  level: "MD"
  disk.path: "./datacache"
  memory.queue {
    #unit(M)
    maxsize: 100
    maxcount: 10000
  }
}
#文件读取策略
file.read.policy {
  #unit(seconds)
  duration: 5
  maxcount: 3000
}

#
resource {
  read.file.thread.num: 5
}
#kafka的配置
kafka {
  serializer.class: "kafka.serializer.DefaultEncoder"
  key.serializer.class: "kafka.serializer.StringEncoder"
  request.required.acks: "1"
  producer.type: "async"
  queue {
    buffering.max.ms: "5000"
    buffering.max.messages: "2000"
    enqueue.timeout.ms: "2000"
  }
  batch.num.messages: "200"
  message.send.max.retries: "10"
  retry.backoff.ms: "1000"
  request.timeout.ms: "10000"
}