#系统的主配置文件
system {
  # 采集器名称,不设默认为HOST名;
  name: "lassock-lily"
  #本机ip或者hostname，如果没设置，则默认使用hostname
  # host: "aleiyeB"
  #ip : "10.7.0.150"
  #mac : "FFFFFFFFFFFF"
  # * 用户ID
  userid: "1"
  authkey: ""
  akka {
    port: 9993
    name: "lassock"
  }
  coursefile : "template/file_course.json"
}
remote {
  zookeeper.url: "localhost:2181"
  host: "localhost"
  register: {
    enabled : false
    port: 6060
    protocolType : "binary"
    transportType: "framed"
    serviceName: "collectorRegister"
  }
  #aleiye-server监控端口
  monitor {
    port:9981
  }
  ping {
  	enabled : false
  }
}


#DB 数据源
datasource{
## jdbc configuration.
  db0 {
    name: collect
    driver: "com.mysql.jdbc.Driver"
    url: "jdbc:mysql://localhost:3306/aleiye?useUnicode=true&characterEncoding=utf-8"
    user: aleiye
    password: cdewsxzaq321
  },

  #解析telnet方式登录，运行命令生成的文件，数据保存到该数据源对应的库中
  db1 {
    name: mysql
    driver: "com.mysql.jdbc.Driver",
    url = "jdbc:mysql://localhost:3306/aleiye?useUnicode=true&characterEncoding=utf-8"
    user = "aleiye"
    password = "cdewsxzaq321"
  }
  db2{
    name: sqlserver
    driver: "com.microsoft.sqlserver.jdbc.SQLServerDriver"
    url: "jdbc:sqlserver://10.160.2.200:1433;DatabaseName=bjbank;"
    user: sa
    password: sa
  }
}
#配置监听器
liveness {
	#class: "com.aleiye.lassock.cache.FileloadLiveness"
    #class: "com.aleiye.lassock.cache.SimpleLocalFileLiveness"
    #class: "com.aleiye.lassock.cache.ZkLiveness"
    class: "com.aleiye.lassock.cache.FilePickLiveness"
}
live: {
	baskets {
		basket0 {
			name : simple
			class : "com.aleiye.lassock.live.basket.MemoryQueueBasket"
		}
		basket1 {
			name : memory
			class : "com.aleiye.lassock.live.basket.MemoryQueueBasket"
		}
		basket2 {
			name : simpleFile
			class : "com.aleiye.lassock.live.basket.MemoryQueueBasket"
		}
		basket3 {
			name : kafkamemory
			class : "com.aleiye.lassock.live.basket.MemoryQueueBasket"
		}
	}
	hills {
	}
	bazaars {
		bazaar0 {
			name : EsBazaar
			basket : simple
			class : "com.aleiye.lassock.live.bazaar.LoggerBazaar"
		}
	}
}
utils{
	es {
		host : "localhost"
		port : 19300
		timeout : 6000
		name : "bank"
	}
}
#执行线程池
executor {
  size: 100,
  maxSize: 100,
  #毫秒
  keepAliveTime: 60000,
  queueSize: 3000
}

#监控
monitor {
  enabled : false
  systemName : "collectorMonitor"
  actorName : "monitor"
  filePath: "temp/monitor.mt",
  period: 30000
}

#标记类型
marker {
  enabled: true,
  class: "com.aleiye.lassock.live.mark.FileMarker",
  filePath: "temp/mark.ofs",
  period: 3000
}

data.storage {
  #M(only memory),D(only disk),MD(memory and disk),JDBC(only jdbc),MJDBC(memory and jdbc)
  level: "MD"
  disk.path: "./datacache"
  memory.queue {
    #unit(M)
    maxsize: 100
    maxcount: 10000
  }
}
bazaar {
  cache.msg.num: 300
  class: "com.aleiye.lassock.live.bazaar.simple.SimpleBazaar"
  akka {
    #unit(second)
    heartbeat.interval: 3
    #unit(second)
    server.dead.interval: 10
    #unit(second)
    callback.interval: 3
  }
  accumulate.persist {
    enable: true
    #local,simple
    type: "local"
    #when the value is "None",we will create the persis use the class.
    class: ""
    #unit:minute
    duration: 5
    batch.num: 10
    data.dir: "./persisData"
    offset.file: "persisOffset.txt"
  }
}
#文件读取策略
file.read.policy {
  #unit(seconds)
  duration: 5
  maxcount: 3000
}

#
resource {
  read.file.thread.num: 5
}
#kafka的配置
kafka {
  serializer.class: "kafka.serializer.DefaultEncoder"
  key.serializer.class: "kafka.serializer.StringEncoder"
  request.required.acks: "1"
  producer.type: "async"
  queue {
    buffering.max.ms: "5000"
    buffering.max.messages: "2000"
    enqueue.timeout.ms: "2000"
  }
  batch.num.messages: "200"
  message.send.max.retries: "10"
  retry.backoff.ms: "1000"
  request.timeout.ms: "10000"
}